{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Spotify Recommendation System Project\n",
    "\n",
    "**Purpose:** Build a scalable music recommendation system using PySpark and Spotify datasets.\n",
    "\n",
    "**Group members:**\n",
    "\n",
    "* Raakin Bhatti\n",
    "* Aneesh Bulusu\n",
    "* Walid Farhat\n",
    "* Long Nguyen\n",
    "* Strahinja Radakovic"
   ],
   "id": "cb7cf3c7af7c3e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "**What is our big data problem? What is our goal?**\n",
    "* Build a scalable music recommendation system using a large dataset of songs and their audio features from Spotify.\n",
    "* Given the names of some songs, the algorithm will predict and recommend songs similar to the input songs based on their audio features (e.g. danceability, energy, acoustics, etc.) and categorical data like genres.\n",
    "* Use Spark/PySpark to process large-scale data and develop machine learning algorithms.\n",
    "\n",
    "**Why we chose building Recommendation Systems:**\n",
    "* Recommendation systems are widely used in modern digital platforms to enhance user experience (e.g., Spotify, Netflix, Amazon).\n",
    "* Help users discover relevant content, which helps to increase engagement and satisfaction.\n",
    "\n",
    "**Why Spotify dataset?**\n",
    "* Spotify is a leading music streaming platform which has rich data on songs, audio features, and artists.\n",
    "* The dataset provides an opportunity to analyze music preferences and recommend personalized songs or playlists.\n",
    "\n",
    "**What is a big data challenge?**\n",
    "* Spotify data involves thousands of users, songs, and interactions, requiring storage and processing at scale.\n",
    "* PySpark is well-suited for handling and analyzing big data with its distributed computing capabilities.\n",
    "\n",
    "**Broader applications:**\n",
    "* Insights from the project can extend to other recommendation systems.\n",
    "* Demonstrates the integration of big data tools and machine learning for real-world applications.\n"
   ],
   "id": "9fc38fc12d35af55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Filtering method:**\n",
    "\n",
    "Our group's recommendation system will use Content-Based Filtering method instead of Collaborative filtering. Content-Based Filtering method analyzes the audio characteristics of songs youâ€™ve previously enjoyed, then the model will make personalized suggestions. We do not use Collaborative filtering or user-based filtering method becuase we cannot collect the information related to Spotify's users such as `user_id`.\n",
    "\n",
    "**What is the Target Variable for this project?**\n",
    "\n",
    "In a content-based recommendation system, we do not have a traditional \"target variable\" like in supervised learning. Instead, the goal is to calculate similarity metrics between songs based on their features. However, you can think of the **song similarity score** (e.g., cosine similarity, Euclidean distance) as the implicit target metric for creating recommendations.\n",
    "\n",
    "* The goal is to recommend songs similar to the input songs based on their audio features and genres.\n",
    "* For our recommendation system, the focus is on matching songs based on audio features like danceability, energy, acousticness, etc., and categorical data like genre.\n",
    "\n",
    "**What are the interesting Features of the dataset?**\n",
    "\n",
    "**Numerical Features (Audio Characteristics):** \n",
    "\n",
    "danceability: Indicates how suitable a track is for dancing.\n",
    "energy: Represents the intensity and activity level of a track.\n",
    "loudness: Measures the decibel level of the track.\n",
    "acousticness: Likelihood of the track being acoustic.\n",
    "instrumentalness: Determines the degree to which a track is instrumental.\n",
    "valence: Describes the musical positiveness conveyed by a track.\n",
    "tempo: The speed of the song in beats per minute (BPM).\n",
    "duration_ms: Song duration, which can help differentiate between shorter and longer tracks.\n",
    "\n",
    "**Categorical Features:**\n",
    "\n",
    "genre: A key factor in identifying similar songs.\n",
    "key: Musical key in which the song is composed.\n",
    "mode: Indicates whether the song is in a major or minor scale.\n",
    "\n",
    "**Meta Information (Optional):**\n",
    "\n",
    "popularity: While not directly linked to audio characteristics, it can serve as a secondary ranking factor in your recommendations.\n",
    "year: Could help in filtering songs by era if needed."
   ],
   "id": "568fb4a87c9e4ee7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Setting up Spark\n",
    "\n",
    "This section is optional. In case that you have not installed Spark, Hadoop, etc. in your local machine, then this part will help setting up Spark in the Jupyter Notebook for running."
   ],
   "id": "9654b2daf089473"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:43:44.057778Z",
     "start_time": "2024-11-27T03:43:44.052906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## OPTIONAL: Setting up Spark in Jupyter Notebook\n",
    "\n",
    "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# !wget https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz\n",
    "# !tar -xvf spark-3.5.3-bin-hadoop3.tgz\n",
    "# !pip install findspark\n",
    "# \n",
    "# import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.3-bin-hadoop3\"\n",
    "# \n",
    "# import findspark\n",
    "# findspark.init()\n",
    "# findspark.find()"
   ],
   "id": "f7c6a9a9e21abfec",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:43:44.089440Z",
     "start_time": "2024-11-27T03:43:44.084021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## OPTIONAL: Test if PySpark is ready to go\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "# \n",
    "# spark = SparkSession.builder.appName(\"Test\").getOrCreate()\n",
    "# print(f\"Spark version:\", spark.version)\n",
    "# \n",
    "# spark.stop()\n",
    "\n",
    "## expected result: 3.5.3 or similar"
   ],
   "id": "4e85d88f72d3ae04",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Collection\n",
    "\n",
    "**Required Tasks:**\n",
    "* Load the dataset into a PySpark DataFrame.\n",
    "* Verify the dataset schema and check if the data is loaded correctly.\n",
    "\n",
    "**Output:** A PySpark DataFrame loaded and ready for processing, with the schema verified.\n"
   ],
   "id": "7bfca0ce77f2b1db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### How we get the dataset?\n",
    "\n",
    "We extracted the dataset from Spotify using Spotify API and the `Spotipy` library in Python.\n",
    "\n",
    "Attached the Python files for extraction and transformation (from JSON to CSV). Please note that these files are for references only, because in order to run those files, you will have to set up a virtual environment."
   ],
   "id": "8a58a580889aaca5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading datasets",
   "id": "f5e7046225ee57ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:43:44.126458Z",
     "start_time": "2024-11-27T03:43:44.112244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ],
   "id": "cefc2a953d7d634c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Program Files\\\\spark-3.5.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:43:51.169634Z",
     "start_time": "2024-11-27T03:43:44.603878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, count\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# initialize a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SpotifyRecommendationSystem\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark version:\", spark.version)"
   ],
   "id": "a1eb65f9c65a3276",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.3\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:44:04.759702Z",
     "start_time": "2024-11-27T03:43:51.225005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load dataset into a DataFrame\n",
    "file_path = \"./dataset/spotify_dataset.csv\" # Note: The dataset file is too large (>250 MB) to commit to a GitHub repo.\n",
    "spotify_df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# display the first few rows\n",
    "spotify_df.show(5)\n"
   ],
   "id": "9bcc09d58d3b4dd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+--------------------+----------+----+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+--------------+\n",
      "|_c0|  artist_name|      track_name|            track_id|popularity|year|   genre|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|duration_ms|time_signature|\n",
      "+---+-------------+----------------+--------------------+----------+----+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+--------------+\n",
      "|  0|   Jason Mraz| I Won't Give Up|53QF56cjZA9RTuuMZ...|        68|2012|acoustic|       0.483| 0.303|  4| -10.058|   1|     0.0429|       0.694|             0.0|   0.115|  0.139|133.406|   240166.0|           3.0|\n",
      "|  1|   Jason Mraz|93 Million Miles|1s8tP3jP4GZcyHDsj...|        50|2012|acoustic|       0.572| 0.454|  3| -10.286|   1|     0.0258|       0.477|        1.37e-05|  0.0974|  0.515|140.182|   216387.0|           4.0|\n",
      "|  2|Joshua Hyslop|Do Not Let Me Go|7BRCa8MPiyuvr2VU3...|        57|2012|acoustic|       0.409| 0.234|  3| -13.711|   1|     0.0323|       0.338|           5e-05|  0.0895|  0.145|139.832|   158960.0|           4.0|\n",
      "|  3| Boyce Avenue|        Fast Car|63wsZUhUZLlh1Osyr...|        58|2012|acoustic|       0.392| 0.251| 10|  -9.845|   1|     0.0363|       0.807|             0.0|  0.0797|  0.508|204.961|   304293.0|           4.0|\n",
      "|  4| Andrew Belle|Sky's Still Blue|6nXIYClvJAfi6ujLi...|        54|2012|acoustic|        0.43| 0.791|  6|  -5.419|   0|     0.0302|      0.0726|          0.0193|    0.11|  0.217|171.864|   244320.0|           4.0|\n",
      "+---+-------------+----------------+--------------------+----------+----+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Inspection and Validation\n",
    "\n",
    "In this section, we will do the following tasks:\n",
    "\n",
    "* Check the data schema with column names and data types.\n",
    "* Convert data types if needed.\n",
    "* Check for the summary statistics of the dataset.\n",
    "* Check for missing values. Handle missing values properly.\n",
    "* Check for outliers. Handle the outliers.\n",
    "* Check for distinct values."
   ],
   "id": "ed3a962387bf81e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:44:04.895775Z",
     "start_time": "2024-11-27T03:44:04.886113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print schema to verify column names and data types\n",
    "spotify_df.printSchema()"
   ],
   "id": "4123d71c842833d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- danceability: string (nullable = true)\n",
      " |-- energy: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- loudness: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- speechiness: string (nullable = true)\n",
      " |-- acousticness: string (nullable = true)\n",
      " |-- instrumentalness: string (nullable = true)\n",
      " |-- liveness: string (nullable = true)\n",
      " |-- valence: double (nullable = true)\n",
      " |-- tempo: double (nullable = true)\n",
      " |-- duration_ms: double (nullable = true)\n",
      " |-- time_signature: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Data type conversins:**\n",
    "\n",
    "From [Spotify's API documentation](https://developer.spotify.com/documentation/web-api/reference/get-audio-features) about track's audio features, each feature has its own meaning and data types. So we will convert the data types of features in our dataset to match Spotify's documentation."
   ],
   "id": "74c1c8744d12f801"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:44:05.809778Z",
     "start_time": "2024-11-27T03:44:05.273426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# casting columns to their appropriate data types as per Spotify's documentation\n",
    "spotify_df = spotify_df \\\n",
    "    .withColumn(\"popularity\", col(\"popularity\").cast(\"int\")) \\\n",
    "    .withColumn(\"year\", col(\"year\").cast(\"int\")) \\\n",
    "    .withColumn(\"danceability\", col(\"danceability\").cast(\"float\")) \\\n",
    "    .withColumn(\"energy\", col(\"energy\").cast(\"float\")) \\\n",
    "    .withColumn(\"key\", col(\"key\").cast(\"int\")) \\\n",
    "    .withColumn(\"loudness\", col(\"loudness\").cast(\"float\")) \\\n",
    "    .withColumn(\"mode\", col(\"mode\").cast(\"int\")) \\\n",
    "    .withColumn(\"speechiness\", col(\"speechiness\").cast(\"float\")) \\\n",
    "    .withColumn(\"acousticness\", col(\"acousticness\").cast(\"float\")) \\\n",
    "    .withColumn(\"instrumentalness\", col(\"instrumentalness\").cast(\"float\")) \\\n",
    "    .withColumn(\"liveness\", col(\"liveness\").cast(\"float\")) \\\n",
    "    .withColumn(\"tempo\", col(\"tempo\").cast(\"float\")) \\\n",
    "    .withColumn(\"time_signature\", col(\"time_signature\").cast(\"int\"))\n",
    "\n",
    "# re-check the updated schema\n",
    "spotify_df.printSchema()\n"
   ],
   "id": "90e820975ec6874d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- popularity: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- danceability: float (nullable = true)\n",
      " |-- energy: float (nullable = true)\n",
      " |-- key: integer (nullable = true)\n",
      " |-- loudness: float (nullable = true)\n",
      " |-- mode: integer (nullable = true)\n",
      " |-- speechiness: float (nullable = true)\n",
      " |-- acousticness: float (nullable = true)\n",
      " |-- instrumentalness: float (nullable = true)\n",
      " |-- liveness: float (nullable = true)\n",
      " |-- valence: double (nullable = true)\n",
      " |-- tempo: float (nullable = true)\n",
      " |-- duration_ms: double (nullable = true)\n",
      " |-- time_signature: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:44:07.409129Z",
     "start_time": "2024-11-27T03:44:05.848539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# count total rows in the dataset\n",
    "total_rows = spotify_df.count()\n",
    "print(f\"Total rows in the dataset: {total_rows}\")"
   ],
   "id": "10707cba07e8edda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in the dataset: 1159764\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Remarks: The dataset contains 1,159,764 rows, which is quite large, indicating the need for big data tools like PySpark.",
   "id": "de887a331b3feed2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Check for Summary Statistics:**\n",
    "\n",
    "Next, we want to check for the summary statistics of the dataset. In [Spark](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.describe.html), if using `.describe()` method, it will by default calculate the stats for all columns including both numerical and non-numerical (string) columns. Therefore, we have to filter out the columns based on their data types as follows."
   ],
   "id": "40fe6fa2e6568d95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:44:16.855866Z",
     "start_time": "2024-11-27T03:44:07.493611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# filter numeric columns using dtypes\n",
    "numeric_columns = [name for name, dtype in spotify_df.dtypes if dtype in ('int', 'bigint', 'double', 'float', 'decimal')]\n",
    "\n",
    "# select only numeric columns\n",
    "numeric_df = spotify_df.select(*numeric_columns)\n",
    "\n",
    "# show summary statistics for numerical columns only\n",
    "numeric_df.describe().show()"
   ],
   "id": "9b3ddea969b36fb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+\n",
      "|summary|              _c0|        popularity|              year|     danceability|            energy|               key|          loudness|             mode|        speechiness|       acousticness|   instrumentalness|           liveness|            valence|             tempo|       duration_ms|    time_signature|\n",
      "+-------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+\n",
      "|  count|          1159764|           1158091|           1159141|          1158580|           1159356|           1159602|           1159670|          1159731|            1159748|            1159756|            1159761|            1159762|            1159764|           1159764|           1159764|           1159764|\n",
      "|   mean|659061.3219129064|18.393719491818864|2010.1450030669264|1.151689557821435|0.8750431817828228| 5.421848185843074| -8.90125644459297|0.642995660200512|0.10187417859253778|0.32384287579000465|0.25511809159462906|0.22280301037863148|0.45543146363409936| 121.2262622110439|249223.50955903548|219.83662710689416|\n",
      "| stddev|428549.1535705906|15.888212092912061| 60.52526727918657|35.12214257953176|21.720800387148365|17.144522698291876|11.435647099557297|7.026148812516287| 5.2942646995895775| 3.2571918436446836|  2.666910391613436| 0.2258207729737689| 0.2759459120284293|30.103371885007203| 149607.9337131288| 8673.273461566454|\n",
      "|    min|                0|                 0|                 0|              0.0|               0.0|                 0|             -58.1|              -43|            -36.843|            -36.639|            -38.845|            -29.312|            -29.777|           -24.073|           -17.417|               -22|\n",
      "|    max|          1473395|               100|              2023|           2023.0|            2023.0|              2023|            2023.0|             2023|             2017.0|             2017.0|             2009.0|               10.0|               11.0|           249.993|         6000495.0|           1358453|\n",
      "+-------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Remarks for summary statistics:**\n",
    "\n",
    "* `popularity`: Ranges from 0 to 100, indicating a reasonable scale for popularity.\n",
    "* `year`: The dataset includes tracks from 0 to 2023. The value 0 seems anomalous and might need further investigation.\n",
    "* Other features like `danceability`, `energy`, `tempo`, and `duration_ms` have a wide range of values, which may need normalization or standardization for machine learning.\n",
    "* Potential outliers: Columns like `tempo` (min = -24.073) and `loudness` (min = -58.1) have unusual values that might indicate outliers or data entry issues."
   ],
   "id": "ce1bd7a6f443e685"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:44:21.860243Z",
     "start_time": "2024-11-27T03:44:16.896673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for missing values in each column\n",
    "missing_values = spotify_df.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c in spotify_df.columns\n",
    "])\n",
    "missing_values.show()"
   ],
   "id": "8566923377d65c27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+--------+----------+----+-----+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-----+-----------+--------------+\n",
      "|_c0|artist_name|track_name|track_id|popularity|year|genre|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|tempo|duration_ms|time_signature|\n",
      "+---+-----------+----------+--------+----------+----+-----+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-----+-----------+--------------+\n",
      "|  0|          0|         0|       0|      1673| 623|    0|        1184|   408|162|      94|  33|         16|           8|               3|       2|      0|    0|          0|             0|\n",
      "+---+-----------+----------+--------+----------+----+-----+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-----+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Remarks for missing values:**\n",
    "\n",
    "* Columns with missing data: popularity (1,673 missing values), year (623), and others such as  danceability, energy, key, loudness, and mode.\n",
    "* Given the dataset has over 1.15M rows, the proportion of missing data is extremely small (less than 0.1% for all affected columns).\n",
    "* In this case, we will drop rows with missing values in features that are critical for our recommendation system."
   ],
   "id": "96848fd8d14259c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:44:25.037764Z",
     "start_time": "2024-11-27T03:44:21.991511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# drop rows with missing data in critical columns\n",
    "columns_to_check = ['popularity', 'year', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness']\n",
    "\n",
    "spotify_df_clean = spotify_df.na.drop(subset=columns_to_check)\n",
    "\n",
    "# verify the number of rows after dropping\n",
    "cleaned_rows = spotify_df_clean.count()\n",
    "print(f\"Rows after dropping missing data: {cleaned_rows}\")\n",
    "\n",
    "dropped_rows = total_rows - cleaned_rows\n",
    "print(f\"Number of rows dropped: {dropped_rows}\")\n"
   ],
   "id": "47e94b8710ab756",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after dropping missing data: 1158091\n",
      "Number of rows dropped: 1673\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Anomalies and Outliers**:\n",
    "\n",
    "We will investigate the folloiwng things:\n",
    "\n",
    "* Check for distinct values of `year` column to make sure no abnormal values (such as 1500).\n",
    "* \n",
    "\n"
   ],
   "id": "2ba0ba961fd386ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:50:19.110174Z",
     "start_time": "2024-11-27T03:50:17.228106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get distinct years and their frequencies\n",
    "year_distribution = spotify_df_clean.groupBy(\"year\").count().orderBy(\"year\")\n",
    "\n",
    "year_distribution.show(50)"
   ],
   "id": "b1e523b5392689d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2000|43944|\n",
      "|2001|42316|\n",
      "|2002|42084|\n",
      "|2003|42250|\n",
      "|2004|43293|\n",
      "|2005|43708|\n",
      "|2006|45419|\n",
      "|2007|45920|\n",
      "|2008|47336|\n",
      "|2009|46810|\n",
      "|2010|46818|\n",
      "|2011|46381|\n",
      "|2012|54725|\n",
      "|2013|53105|\n",
      "|2014|53120|\n",
      "|2015|51569|\n",
      "|2016|40246|\n",
      "|2017|56171|\n",
      "|2018|56541|\n",
      "|2019|55739|\n",
      "|2020|55035|\n",
      "|2021|53529|\n",
      "|2022|53637|\n",
      "|2023|38395|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Remarks for `year`: The years range from 2000 to 2023, which are expected and normal.",
   "id": "a854ab265f1643f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Check for anomalies in numerical columns:**\n",
    "\n",
    "Compare data against the value ranges specified in the [Spotify documentation](https://developer.spotify.com/documentation/web-api/reference/get-audio-features):\n",
    "* acousticness: [0, 1]\n",
    "* danceability: [0, 1]\n",
    "* energy: [0, 1] \n",
    "* instrumentalness: [0, 1]\n",
    "* key: [-1, 11]\n",
    "* liveness: [0, 1]\n",
    "* mode: {0, 1}\n",
    "* speechiness: [0, 1]\n",
    "* tempo: Typically [1, 250], (note: this is a typical range; Spotify docs don't strictly enforce this.)\n",
    "* time_signature: [3, 7]\n",
    "* valence: [0, 1]"
   ],
   "id": "24aac1c3616ec577"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:51:02.426072Z",
     "start_time": "2024-11-27T03:50:52.908829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the range checks for each feature\n",
    "range_checks = {\n",
    "    \"acousticness\": (0, 1),\n",
    "    \"danceability\": (0, 1),\n",
    "    \"energy\": (0, 1),\n",
    "    \"instrumentalness\": (0, 1),\n",
    "    \"key\": (-1, 11),\n",
    "    \"liveness\": (0, 1),\n",
    "    \"mode\": (0, 1),\n",
    "    \"speechiness\": (0, 1),\n",
    "    \"tempo\": (1, 350),\n",
    "    \"time_signature\": (3, 7),\n",
    "    \"valence\": (0, 1),\n",
    "}\n",
    "\n",
    "# identify anomalies in each feature\n",
    "anomalies = {}\n",
    "for feature, (min_val, max_val) in range_checks.items():\n",
    "    anomalies[feature] = spotify_df_clean.filter((col(feature) < min_val) | (col(feature) > max_val)).count()\n",
    "\n",
    "# print the anomalies count for each feature\n",
    "for feature, count in anomalies.items():\n",
    "    print(f\"Number of anomalies in {feature}: {count}\")\n"
   ],
   "id": "99b55d3ed6c61adf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalies in acousticness: 0\n",
      "Number of anomalies in danceability: 0\n",
      "Number of anomalies in energy: 0\n",
      "Number of anomalies in instrumentalness: 0\n",
      "Number of anomalies in key: 0\n",
      "Number of anomalies in liveness: 0\n",
      "Number of anomalies in mode: 0\n",
      "Number of anomalies in speechiness: 0\n",
      "Number of anomalies in tempo: 1198\n",
      "Number of anomalies in time_signature: 13816\n",
      "Number of anomalies in valence: 0\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "From the results:\n",
    "\n",
    "* No Anomalies:\n",
    "    * Most features (acousticness, danceability, energy, instrumentalness, etc.) have no anomalies. These are clean and can be used as-is.\n",
    "* tempo Anomalies:\n",
    "    * 1,198 anomalies fall outside the range [1, 250]. These might include invalid or outlier values (e.g., extremely high or low BPM).\n",
    "* time_signature Anomalies:\n",
    "    * 13,816 anomalies fall outside the range [3, 7]. These could represent tracks with unusual time signatures, potentially errors or special cases."
   ],
   "id": "875d6ac86a79c69f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T03:51:51.146081Z",
     "start_time": "2024-11-27T03:51:50.168917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show rows with tempo anomalies\n",
    "tempo_anomalies = spotify_df_clean.filter((col(\"tempo\") < 1) | (col(\"tempo\") > 350))\n",
    "\n",
    "# Descriptive statistics for tempo anomalies\n",
    "tempo_anomalies.describe(\"tempo\").show()\n"
   ],
   "id": "d00741f3b2fbb380",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|summary|tempo|\n",
      "+-------+-----+\n",
      "|  count| 1198|\n",
      "|   mean|  0.0|\n",
      "| stddev|  0.0|\n",
      "|    min|  0.0|\n",
      "|    max|  0.0|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Remarks for Tempo:**\n",
    "\n",
    "* As you can see, the min and max values of tempo anomalies are 0.0, which means these values are missing in the dataset (i.e. 0.0 == missing values). We can eliminate them since the quantity is very small in the dataset."
   ],
   "id": "249dfb69963fa5e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T23:22:26.392807Z",
     "start_time": "2024-11-18T23:22:25.456846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show rows with time_signature anomalies\n",
    "time_signature_anomalies = spotify_df_clean.filter((col(\"time_signature\") < 3) | (col(\"time_signature\") > 7))\n",
    "\n",
    "# Descriptive statistics for time_signature anomalies\n",
    "time_signature_anomalies.describe(\"time_signature\").show()\n"
   ],
   "id": "979f1c940d61d660",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|     time_signature|\n",
      "+-------+-------------------+\n",
      "|  count|              13816|\n",
      "|   mean| 0.9111899247249565|\n",
      "| stddev|0.28447970650303633|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Distinct values**\n",
    "\n",
    "Let's check the distinct values in the most important columns: `artist_name`, `track_name`, `genre`."
   ],
   "id": "5e5b6b8d65f022c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T04:00:58.629468Z",
     "start_time": "2024-11-27T04:00:53.469627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count distinct values in key columns\n",
    "key_columns = ['artist_name', 'track_name', 'genre']\n",
    "distinct_counts = {col_name: spotify_df.select(col_name).distinct().count() for col_name in key_columns}\n",
    "\n",
    "for col_name, count in distinct_counts.items():\n",
    "    print(f\"Distinct values in {col_name}: {count}\")"
   ],
   "id": "247b305f4ada2822",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values in artist_name: 64159\n",
      "Distinct values in track_name: 882285\n",
      "Distinct values in genre: 392\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "baef496f7594381b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Filtering\n",
    "\n",
    "In this section, we will identify and retain only the relevant features for building the recommendation system. We will consider dropping irrelevant or redundant columns like `_c0` that may not contribute to the model.\n",
    "\n",
    "* Given that `time_signature` feature has more than 13K values of anamolies and has little importance to finding similarities between songs, we will drop this feature.\n",
    "* `_c0` feature is only the index of the dataset and will contribute to the model so we will drop it."
   ],
   "id": "8aa5692fb3749b56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T04:10:04.352406Z",
     "start_time": "2024-11-27T04:10:04.126662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# retain only relevant features for the recommendation system\n",
    "selected_columns = [\n",
    "    'artist_name', 'track_name', 'track_id', 'popularity', 'year', \n",
    "    'genre', 'danceability', 'energy', 'key', 'loudness', 'mode', \n",
    "    'speechiness', 'acousticness', 'instrumentalness', 'liveness', \n",
    "    'valence', 'tempo', 'duration_ms'\n",
    "]\n",
    "\n",
    "# create a filtered DataFrame\n",
    "spotify_df_filtered = spotify_df_clean.select(*selected_columns)\n",
    "\n",
    "# show the schema of the filtered DataFrame\n",
    "spotify_df_filtered.printSchema()\n",
    "\n",
    "# verify the filtering process\n",
    "spotify_df_filtered.show(5)\n"
   ],
   "id": "d129fe4ebe4819e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- popularity: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- danceability: float (nullable = true)\n",
      " |-- energy: float (nullable = true)\n",
      " |-- key: integer (nullable = true)\n",
      " |-- loudness: float (nullable = true)\n",
      " |-- mode: integer (nullable = true)\n",
      " |-- speechiness: float (nullable = true)\n",
      " |-- acousticness: float (nullable = true)\n",
      " |-- instrumentalness: float (nullable = true)\n",
      " |-- liveness: float (nullable = true)\n",
      " |-- valence: double (nullable = true)\n",
      " |-- tempo: float (nullable = true)\n",
      " |-- duration_ms: double (nullable = true)\n",
      "\n",
      "+-------------+----------------+--------------------+----------+----+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+\n",
      "|  artist_name|      track_name|            track_id|popularity|year|   genre|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|duration_ms|\n",
      "+-------------+----------------+--------------------+----------+----+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+\n",
      "|   Jason Mraz| I Won't Give Up|53QF56cjZA9RTuuMZ...|        68|2012|acoustic|       0.483| 0.303|  4| -10.058|   1|     0.0429|       0.694|             0.0|   0.115|  0.139|133.406|   240166.0|\n",
      "|   Jason Mraz|93 Million Miles|1s8tP3jP4GZcyHDsj...|        50|2012|acoustic|       0.572| 0.454|  3| -10.286|   1|     0.0258|       0.477|         1.37E-5|  0.0974|  0.515|140.182|   216387.0|\n",
      "|Joshua Hyslop|Do Not Let Me Go|7BRCa8MPiyuvr2VU3...|        57|2012|acoustic|       0.409| 0.234|  3| -13.711|   1|     0.0323|       0.338|          5.0E-5|  0.0895|  0.145|139.832|   158960.0|\n",
      "| Boyce Avenue|        Fast Car|63wsZUhUZLlh1Osyr...|        58|2012|acoustic|       0.392| 0.251| 10|  -9.845|   1|     0.0363|       0.807|             0.0|  0.0797|  0.508|204.961|   304293.0|\n",
      "| Andrew Belle|Sky's Still Blue|6nXIYClvJAfi6ujLi...|        54|2012|acoustic|        0.43| 0.791|  6|  -5.419|   0|     0.0302|      0.0726|          0.0193|    0.11|  0.217|171.864|   244320.0|\n",
      "+-------------+----------------+--------------------+----------+----+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5b651c9d6dcd98c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Transformations\n",
    "\n",
    "Here are the goals of this section:\n",
    "\n",
    "1. Handle categorical features: Features like `genre` and `artist_name` are categorical and need to be encoded to numeric values for modeling.\n",
    "2. Normalize or scale numeric features: Features like `danceability`, `energy`, `tempo`, etc., may have varying ranges, which can affect model performance. Normalize or standardize these values.\n",
    "3. Generate additional features (if needed): Create new features based on existing ones. For example, you might engineer a feature for \"popularity bucket\" if grouping songs by popularity levels makes sense for your recommendation algorithm."
   ],
   "id": "cb996db1b9e070f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Encoding categorial features\n",
    "\n",
    "We will encode `genre` and `artist_name` to numeric values using PySpark's `StringIndexer`."
   ],
   "id": "e93e75eb10447385"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T04:36:39.952110Z",
     "start_time": "2024-11-27T04:36:38.749339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## First, we want to see the unique values in the 'genre' column \n",
    "\n",
    "# group by 'genre', count occurrences, and order by count in descending order\n",
    "genre_counts = spotify_df.groupBy(\"genre\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "genre_counts.show(10)"
   ],
   "id": "d1141e8f8a66628",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|      genre|count|\n",
      "+-----------+-----+\n",
      "|black-metal|21852|\n",
      "|     gospel|21621|\n",
      "|    ambient|21385|\n",
      "|   acoustic|21095|\n",
      "|   alt-rock|20917|\n",
      "|        emo|20840|\n",
      "|     indian|20580|\n",
      "|      k-pop|19994|\n",
      "|    new-age|19908|\n",
      "|      blues|19682|\n",
      "+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Remarks for genre's unique values:** The distinct values in the genre column are single-valued entries, including words with hyphens such as \"black-metal\", \"alt-rock\", \"new-age\", etc. These hyphenated values are treated as single entities and do not represent multi-valued genres. Therefore, we can safely proceed with encoding this column using StringIndexer without needing to preprocess or split multi-valued genres. This will simplify the encoding process and ensures that each genre maps to a single, unique numeric value.",
   "id": "7fe764a9dbfe5c22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T04:26:33.530629Z",
     "start_time": "2024-11-27T04:26:32.595044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# encode the 'genre' column\n",
    "genre_indexer = StringIndexer(inputCol=\"genre\", outputCol=\"genre_index\")\n",
    "spotify_df_encoded = genre_indexer.fit(spotify_df_filtered).transform(spotify_df_filtered)\n",
    "\n",
    "# verify the encoding of a few rows\n",
    "spotify_df_encoded.select(\"genre\", \"genre_index\").show(10)\n"
   ],
   "id": "c7dfc76b8912fdc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|   genre|genre_index|\n",
      "+--------+-----------+\n",
      "|acoustic|        3.0|\n",
      "|acoustic|        3.0|\n",
      "|acoustic|        3.0|\n",
      "|acoustic|        3.0|\n",
      "|acoustic|        3.0|\n",
      "|acoustic|        3.0|\n",
      "|acoustic|        3.0|\n",
      "|acoustic|        3.0|\n",
      "|acoustic|        3.0|\n",
      "|acoustic|        3.0|\n",
      "+--------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T04:41:53.775783Z",
     "start_time": "2024-11-27T04:41:52.493036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## View the distinct values of genre and their corresponding genre_index\n",
    "\n",
    "distinct_genre_mapping = spotify_df_encoded.select(\"genre\", \"genre_index\").distinct()\n",
    "\n",
    "distinct_genre_mapping = distinct_genre_mapping.orderBy(\"genre_index\")\n",
    "\n",
    "distinct_genre_mapping.show(10, truncate=False)"
   ],
   "id": "23be2b042fbc0567",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|genre      |genre_index|\n",
      "+-----------+-----------+\n",
      "|black-metal|0.0        |\n",
      "|gospel     |1.0        |\n",
      "|ambient    |2.0        |\n",
      "|acoustic   |3.0        |\n",
      "|alt-rock   |4.0        |\n",
      "|emo        |5.0        |\n",
      "|indian     |6.0        |\n",
      "|k-pop      |7.0        |\n",
      "|new-age    |8.0        |\n",
      "|blues      |9.0        |\n",
      "+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T04:41:39.901639Z",
     "start_time": "2024-11-27T04:41:38.341297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Check the unique values in the 'artist_name' column \n",
    "\n",
    "# group by 'genre', count occurrences, and order by count in descending order\n",
    "artist_name_counts = spotify_df.groupBy(\"artist_name\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "artist_name_counts.show(10)"
   ],
   "id": "3be9f0500a7ae216",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         artist_name|count|\n",
      "+--------------------+-----+\n",
      "|         Traditional| 4058|\n",
      "|       Grateful Dead| 2320|\n",
      "|Johann Sebastian ...| 2125|\n",
      "|   Giacomo Meyerbeer| 1345|\n",
      "|       Elvis Presley| 1242|\n",
      "|Wolfgang Amadeus ...| 1084|\n",
      "|    Armin van Buuren| 1061|\n",
      "|     Astor Piazzolla|  932|\n",
      "|         Hans Zimmer|  863|\n",
      "|       Andrei Krylov|  841|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T04:42:00.251085Z",
     "start_time": "2024-11-27T04:41:59.678276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# encode the 'artist_name' column\n",
    "artist_indexer = StringIndexer(inputCol=\"artist_name\", outputCol=\"artist_index\")\n",
    "spotify_df_encoded = artist_indexer.fit(spotify_df_encoded).transform(spotify_df_encoded)\n"
   ],
   "id": "ae2baf9e1ebbbfab",
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Output column artist_index already exists.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIllegalArgumentException\u001B[0m                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# encode the 'artist_name' column\u001B[39;00m\n\u001B[0;32m      2\u001B[0m artist_indexer \u001B[38;5;241m=\u001B[39m StringIndexer(inputCol\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124martist_name\u001B[39m\u001B[38;5;124m\"\u001B[39m, outputCol\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124martist_index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m spotify_df_encoded \u001B[38;5;241m=\u001B[39m \u001B[43martist_indexer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspotify_df_encoded\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtransform(spotify_df_encoded)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# View the distinct values of artist_name and their corresponding artist_index\u001B[39;00m\n\u001B[0;32m      6\u001B[0m distinct_artist_mapping \u001B[38;5;241m=\u001B[39m spotify_df_encoded\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124martist_name\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124martist_index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mdistinct()\n",
      "File \u001B[1;32mC:\\Program Files\\spark-3.5.3\\python\\pyspark\\ml\\base.py:205\u001B[0m, in \u001B[0;36mEstimator.fit\u001B[1;34m(self, dataset, params)\u001B[0m\n\u001B[0;32m    203\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy(params)\u001B[38;5;241m.\u001B[39m_fit(dataset)\n\u001B[0;32m    204\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 205\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    208\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    209\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mtype\u001B[39m(params)\n\u001B[0;32m    210\u001B[0m     )\n",
      "File \u001B[1;32mC:\\Program Files\\spark-3.5.3\\python\\pyspark\\ml\\wrapper.py:381\u001B[0m, in \u001B[0;36mJavaEstimator._fit\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_fit\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset: DataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m JM:\n\u001B[1;32m--> 381\u001B[0m     java_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_java\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    382\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_model(java_model)\n\u001B[0;32m    383\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_copyValues(model)\n",
      "File \u001B[1;32mC:\\Program Files\\spark-3.5.3\\python\\pyspark\\ml\\wrapper.py:378\u001B[0m, in \u001B[0;36mJavaEstimator._fit_java\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m    375\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_java_obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    377\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transfer_params_to_java()\n\u001B[1;32m--> 378\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_java_obj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\spark-3.5.3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[0;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[1;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[0;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32mC:\\Program Files\\spark-3.5.3\\python\\pyspark\\errors\\exceptions\\captured.py:185\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[1;34m(*a, **kw)\u001B[0m\n\u001B[0;32m    181\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[1;32m--> 185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mIllegalArgumentException\u001B[0m: requirement failed: Output column artist_index already exists."
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T04:42:17.523914Z",
     "start_time": "2024-11-27T04:42:15.431882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# View the distinct values of artist_name and their corresponding artist_index\n",
    "distinct_artist_mapping = spotify_df_encoded.select(\"artist_name\", \"artist_index\").distinct()\n",
    "\n",
    "distinct_artist_mapping = distinct_artist_mapping.orderBy(\"artist_index\")\n",
    "\n",
    "distinct_artist_mapping.show(10, truncate=False)"
   ],
   "id": "b64af45cb10016ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------------+\n",
      "|artist_name            |artist_index|\n",
      "+-----------------------+------------+\n",
      "|Traditional            |0.0         |\n",
      "|Grateful Dead          |1.0         |\n",
      "|Johann Sebastian Bach  |2.0         |\n",
      "|Giacomo Meyerbeer      |3.0         |\n",
      "|Elvis Presley          |4.0         |\n",
      "|Armin van Buuren       |5.0         |\n",
      "|Wolfgang Amadeus Mozart|6.0         |\n",
      "|Astor Piazzolla        |7.0         |\n",
      "|Hans Zimmer            |8.0         |\n",
      "|Andrei Krylov          |9.0         |\n",
      "+-----------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T04:44:26.634508Z",
     "start_time": "2024-11-27T04:44:26.355322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## OPTIONAL: \n",
    "# drop the original categorical columns to avoid redundancy (optional)\n",
    "spotify_df_transformed = spotify_df_encoded.drop(\"genre\", \"artist_name\")\n",
    "\n",
    "# Verify encoding\n",
    "spotify_df_transformed.show(5)"
   ],
   "id": "40bb4ccfdd242ea1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+----------+----+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+-----------+------------+\n",
      "|      track_name|            track_id|popularity|year|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|duration_ms|genre_index|artist_index|\n",
      "+----------------+--------------------+----------+----+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+-----------+------------+\n",
      "| I Won't Give Up|53QF56cjZA9RTuuMZ...|        68|2012|       0.483| 0.303|  4| -10.058|   1|     0.0429|       0.694|             0.0|   0.115|  0.139|133.406|   240166.0|        3.0|       461.0|\n",
      "|93 Million Miles|1s8tP3jP4GZcyHDsj...|        50|2012|       0.572| 0.454|  3| -10.286|   1|     0.0258|       0.477|         1.37E-5|  0.0974|  0.515|140.182|   216387.0|        3.0|       461.0|\n",
      "|Do Not Let Me Go|7BRCa8MPiyuvr2VU3...|        57|2012|       0.409| 0.234|  3| -13.711|   1|     0.0323|       0.338|          5.0E-5|  0.0895|  0.145|139.832|   158960.0|        3.0|      4401.0|\n",
      "|        Fast Car|63wsZUhUZLlh1Osyr...|        58|2012|       0.392| 0.251| 10|  -9.845|   1|     0.0363|       0.807|             0.0|  0.0797|  0.508|204.961|   304293.0|        3.0|        98.0|\n",
      "|Sky's Still Blue|6nXIYClvJAfi6ujLi...|        54|2012|        0.43| 0.791|  6|  -5.419|   0|     0.0302|      0.0726|          0.0193|    0.11|  0.217|171.864|   244320.0|        3.0|      3862.0|\n",
      "+----------------+--------------------+----------+----+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T04:45:24.417711Z",
     "start_time": "2024-11-27T04:45:24.258199Z"
    }
   },
   "cell_type": "code",
   "source": "spotify_df_encoded.show(5)",
   "id": "c5cdcc8f53b389f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+--------------------+----------+----+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+-----------+------------+\n",
      "|  artist_name|      track_name|            track_id|popularity|year|   genre|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|duration_ms|genre_index|artist_index|\n",
      "+-------------+----------------+--------------------+----------+----+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+-----------+------------+\n",
      "|   Jason Mraz| I Won't Give Up|53QF56cjZA9RTuuMZ...|        68|2012|acoustic|       0.483| 0.303|  4| -10.058|   1|     0.0429|       0.694|             0.0|   0.115|  0.139|133.406|   240166.0|        3.0|       461.0|\n",
      "|   Jason Mraz|93 Million Miles|1s8tP3jP4GZcyHDsj...|        50|2012|acoustic|       0.572| 0.454|  3| -10.286|   1|     0.0258|       0.477|         1.37E-5|  0.0974|  0.515|140.182|   216387.0|        3.0|       461.0|\n",
      "|Joshua Hyslop|Do Not Let Me Go|7BRCa8MPiyuvr2VU3...|        57|2012|acoustic|       0.409| 0.234|  3| -13.711|   1|     0.0323|       0.338|          5.0E-5|  0.0895|  0.145|139.832|   158960.0|        3.0|      4401.0|\n",
      "| Boyce Avenue|        Fast Car|63wsZUhUZLlh1Osyr...|        58|2012|acoustic|       0.392| 0.251| 10|  -9.845|   1|     0.0363|       0.807|             0.0|  0.0797|  0.508|204.961|   304293.0|        3.0|        98.0|\n",
      "| Andrew Belle|Sky's Still Blue|6nXIYClvJAfi6ujLi...|        54|2012|acoustic|        0.43| 0.791|  6|  -5.419|   0|     0.0302|      0.0726|          0.0193|    0.11|  0.217|171.864|   244320.0|        3.0|      3862.0|\n",
      "+-------------+----------------+--------------------+----------+----+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Normalize Numerical Features\n",
    "\n",
    "We will normalize numerical features like `danceability`, `energy`, `tempo`, etc., to have values between 0 and 1 using `MinMaxScaler`.\n",
    "\n",
    "There are a few reasons why we should do scaling for these numerical values:\n",
    "\n",
    "* Scaling helps to ensure consistency across features, which measn that all features contribute equally during model training, especially for distance-based algorithms.\n",
    "* Scaling helps to standardize different scales across features. For example, features like `loudness` (negative values) and `tempo` (positive, larger range) have much different scales.\n",
    "* Scaling also improves model performance because many ML algorithms, such as neural networks and matrix factorization (used in recommendation systems), will converge faster and perform better with normalized input data."
   ],
   "id": "9016b2d4022533ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T04:52:27.403662Z",
     "start_time": "2024-11-27T04:52:25.067545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.ml.feature import MinMaxScaler, VectorAssembler\n",
    "\n",
    "# assemble all numerical features into a single vector\n",
    "numeric_features = [\n",
    "    'danceability', 'energy', 'key', 'loudness', 'mode', \n",
    "    'speechiness', 'acousticness', 'instrumentalness', 'liveness', \n",
    "    'valence', 'tempo', 'duration_ms', 'popularity'\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numeric_features, outputCol=\"features_vector\")\n",
    "spotify_df_vectorized = assembler.transform(spotify_df_encoded)\n",
    "\n",
    "# normalize the feature vector\n",
    "scaler = MinMaxScaler(inputCol=\"features_vector\", outputCol=\"scaled_features\")\n",
    "scaler_model = scaler.fit(spotify_df_vectorized)\n",
    "spotify_df_normalized = scaler_model.transform(spotify_df_vectorized)\n",
    "\n",
    "# keep only the scaled features and other relevant columns\n",
    "final_columns = ['track_id', 'year', 'scaled_features', 'genre_index', 'artist_index']\n",
    "spotify_df_final = spotify_df_normalized.select(*final_columns)\n",
    "\n",
    "# Verify the final transformed DataFrame\n",
    "spotify_df_final.show(5)\n"
   ],
   "id": "5e0abf295b17d410",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------------------+-----------+------------+\n",
      "|            track_id|year|     scaled_features|genre_index|artist_index|\n",
      "+--------------------+----+--------------------+-----------+------------+\n",
      "|53QF56cjZA9RTuuMZ...|2012|[0.48640485840895...|        3.0|       461.0|\n",
      "|1s8tP3jP4GZcyHDsj...|2012|[0.57603226934337...|        3.0|       461.0|\n",
      "|7BRCa8MPiyuvr2VU3...|2012|[0.41188320370473...|        3.0|      4401.0|\n",
      "|63wsZUhUZLlh1Osyr...|2012|[0.39476334464300...|        3.0|        98.0|\n",
      "|6nXIYClvJAfi6ujLi...|2012|[0.43303123841708...|        3.0|      3862.0|\n",
      "+--------------------+----+--------------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Verify data preparation\n",
    "\n",
    "Before proceeding with EDA, we have to thoroughly verify the data to ensure everything is ready for the next steps, such as EDA. Weâ€™ll conduct the following checks:\n",
    "\n",
    "1. check for missing values.\n",
    "2. verify data types.\n",
    "3. check for outliers.\n",
    "4. verify data balancing. This menas that, if needed, we will verify that categorical features like genre_index or year are reasonably balanced. This ensures the recommendation system wonâ€™t be biased."
   ],
   "id": "353036e77ba41e7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T04:57:26.826372Z",
     "start_time": "2024-11-27T04:57:25.422816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "\n",
    "# check for missing or null values in each column\n",
    "missing_values_check = spotify_df_final.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c in spotify_df_final.columns\n",
    "])\n",
    "\n",
    "# show results\n",
    "missing_values_check.show()\n"
   ],
   "id": "ce94d3a40223ebdd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+---------------+-----------+------------+\n",
      "|track_id|year|scaled_features|genre_index|artist_index|\n",
      "+--------+----+---------------+-----------+------------+\n",
      "|       0|   0|              0|          0|           0|\n",
      "+--------+----+---------------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T04:57:41.734490Z",
     "start_time": "2024-11-27T04:57:41.727588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print schema to verify data types\n",
    "spotify_df_final.printSchema()\n"
   ],
   "id": "df69b82d73071808",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- scaled_features: vector (nullable = true)\n",
      " |-- genre_index: double (nullable = false)\n",
      " |-- artist_index: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:08:18.292133Z",
     "start_time": "2024-11-27T05:08:14.999442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import count, countDistinct, min, max\n",
    "\n",
    "# check distinct values of genre_index and artist_index\n",
    "spotify_df_final.select(\"genre_index\").distinct().show()\n",
    "spotify_df_final.select(\"artist_index\").distinct().show()\n"
   ],
   "id": "523daf56a43148f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|genre_index|\n",
      "+-----------+\n",
      "|       70.0|\n",
      "|        8.0|\n",
      "|       67.0|\n",
      "|        0.0|\n",
      "|       69.0|\n",
      "|        7.0|\n",
      "|       49.0|\n",
      "|       29.0|\n",
      "|       75.0|\n",
      "|       64.0|\n",
      "|       47.0|\n",
      "|       42.0|\n",
      "|       44.0|\n",
      "|       35.0|\n",
      "|       62.0|\n",
      "|       18.0|\n",
      "|       80.0|\n",
      "|        1.0|\n",
      "|       39.0|\n",
      "|       37.0|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------+\n",
      "|artist_index|\n",
      "+------------+\n",
      "|       496.0|\n",
      "|       596.0|\n",
      "|      4800.0|\n",
      "|      8779.0|\n",
      "|       769.0|\n",
      "|      7554.0|\n",
      "|      5858.0|\n",
      "|     34033.0|\n",
      "|     10681.0|\n",
      "|      9923.0|\n",
      "|     10930.0|\n",
      "|     20467.0|\n",
      "|      5776.0|\n",
      "|     20974.0|\n",
      "|     13956.0|\n",
      "|      6433.0|\n",
      "|     20893.0|\n",
      "|      5983.0|\n",
      "|     14452.0|\n",
      "|     20864.0|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:01:38.353741Z",
     "start_time": "2024-11-27T05:01:35.956111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# count the number of records per genre\n",
    "spotify_df_final.groupBy(\"genre_index\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "# count the number of records per year\n",
    "spotify_df_final.groupBy(\"year\").count().orderBy(\"year\").show()\n"
   ],
   "id": "b1efd0aa10139292",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|genre_index|count|\n",
      "+-----------+-----+\n",
      "|        0.0|21852|\n",
      "|        1.0|21621|\n",
      "|        2.0|21385|\n",
      "|        3.0|21095|\n",
      "|        4.0|20917|\n",
      "|        5.0|20840|\n",
      "|        6.0|20580|\n",
      "|        7.0|19994|\n",
      "|        8.0|19908|\n",
      "|        9.0|19682|\n",
      "|       10.0|19379|\n",
      "|       11.0|19327|\n",
      "|       12.0|19153|\n",
      "|       13.0|18905|\n",
      "|       14.0|18788|\n",
      "|       15.0|18784|\n",
      "|       16.0|18592|\n",
      "|       17.0|18474|\n",
      "|       18.0|18037|\n",
      "|       19.0|17958|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2000|43944|\n",
      "|2001|42316|\n",
      "|2002|42084|\n",
      "|2003|42250|\n",
      "|2004|43293|\n",
      "|2005|43708|\n",
      "|2006|45419|\n",
      "|2007|45920|\n",
      "|2008|47336|\n",
      "|2009|46810|\n",
      "|2010|46818|\n",
      "|2011|46381|\n",
      "|2012|54725|\n",
      "|2013|53105|\n",
      "|2014|53120|\n",
      "|2015|51569|\n",
      "|2016|40246|\n",
      "|2017|56171|\n",
      "|2018|56541|\n",
      "|2019|55739|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**REmarks for data balancing:**\n",
    "\n",
    "* The distribution of `genre_index` is fairly balanced. No single genre dominates excessively, which ensures the dataset won't introduce significant bias in training the model.\n",
    "* The `year` distribution is also reasonably balanced, except for some variation in track counts across years. For example, 2012 to 2019 have slightly higher counts compared to earlier years. This could imply more recent data collection or increased music production in those years. In conclusion, the distribution of `genre_index` and `year` looks good, and we can proceed without additional rebalancing."
   ],
   "id": "cb7432aa0eb7f4e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "504e19883aa0b5e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exploratory Data Analysis (EDA) - IN PROGRESS\n",
    "\n",
    "In this section, we will explore the dataset to find any patterns and correlations in the dataset. We will use some visualizations to show the trends and also validate the preprocessing in ealier steps.\n",
    "\n",
    "Here are some tasks that we will perform:\n",
    "\n",
    "* Check the distribution of numerical features.\n",
    "* Correlation analysis.\n",
    "* Analyze the popularity trends over year and by genre.\n",
    "* Check the distribution by genre.\n",
    "* Plot the relationship between enegery and danceability.\n",
    "* Plot the relationship between valence and tempo.\n",
    "* etc."
   ],
   "id": "371d103682e4c25e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Distribution of numerical features\n",
    "\n",
    "In this section, we will check the distribution of important numerical features (e.g., popularity, danceability, tempo, valence) to understand data spread and skewness.\n",
    "\n",
    "More info about each audio feature can be found in [Spotify's API documentation](https://developer.spotify.com/documentation/web-api/reference/get-audio-features).\n",
    "\n",
    "Reasons to choose these numerical features:\n",
    "\n",
    "* Popularity: This is a key metric for user preference and relevance. Tracks with higher popularity are more likely to be recommended.\n",
    "* Danceability: This feature reflects how suitable a track is for dancingâ€”an important factor in user satisfaction for genres like pop or electronic.\n",
    "* Energy: This feature shows the intensity and activity level of a song, which can help classify songs by mood or genre (e.g., calm vs. energetic).\n",
    "* Tempo: This is the speed of a song. THis is a key factor for many users when selecting playlists (e.g., playlists for workout, study, or relaxation).\n",
    "* Valence: This indicates the emotional tone of the song (happy vs. sad), important for personalized recommendations based on mood. \n",
    "* Duration (`duration_ms`): This feature is relevant for filtering or grouping songs by length (e.g., short tracks for a quick playlist or long tracks for background music)."
   ],
   "id": "689a88834a73f585"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select numerical features to visualize\n",
    "numerical_features = [\"popularity\", \"danceability\", \"energy\", \"tempo\", \"valence\", \"duration_ms\"]\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas for plotting\n",
    "numerical_data = spotify_df.select(numerical_features).sample(fraction=0.01).toPandas()\n",
    "\n",
    "# Plot histograms for each feature\n",
    "for feature in numerical_features:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(numerical_data[feature].dropna(), bins=30, alpha=0.7)\n",
    "    plt.title(f\"Distribution of {feature}\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ],
   "id": "6c6974063fd68271",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4df259b618c8865e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Correlation analysis - IN PROGRSS",
   "id": "5a75d4e5f57d5b6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pandas as pd\n",
    "\n",
    "# Assemble features into a vector for correlation computation\n",
    "vector_col = \"features_vector\"\n",
    "assembler = VectorAssembler(inputCols=numerical_features, outputCol=vector_col)\n",
    "spotify_df_vector = assembler.transform(spotify_df.select(numerical_features))\n",
    "\n",
    "# Compute Pearson correlation matrix\n",
    "correlation_matrix = Correlation.corr(spotify_df_vector, vector_col, \"pearson\").head()[0].toArray()\n",
    "\n",
    "# Convert to Pandas DataFrame for easier visualization\n",
    "correlation_df = pd.DataFrame(correlation_matrix, columns=numerical_features, index=numerical_features)\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_df)\n",
    "\n",
    "# Visualize the correlation matrix\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_df, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n"
   ],
   "id": "e0070e0cbc80767e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f11feec1ea4f4c72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4b7469c978508953"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# In progres\n",
    "# min-max scaling for numerical features\n",
    "\n",
    "from pyspark.ml.feature import MinMaxScaler, VectorAssembler\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(inputCols=['danceability', 'energy'], outputCol='features_raw')\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "scaler = MinMaxScaler(inputCol='features_raw', outputCol='features_scaled')\n",
    "scaler_model = scaler.fit(df)\n",
    "df_scaled = scaler_model.transform(df)\n"
   ],
   "id": "d1ca26ff59fedfe7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
