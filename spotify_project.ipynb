{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Spotify Recommendation System Project\n",
    "\n",
    "**Purpose:** Build a scalable music recommendation system using PySpark and Spotify datasets.\n",
    "\n",
    "**Group members:**\n",
    "\n",
    "* Raakin Bhatti\n",
    "* Aneesh Bulusu\n",
    "* Walid Farhat\n",
    "* Long Nguyen\n",
    "* Strahinja Radakovic"
   ],
   "id": "cb7cf3c7af7c3e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "**What is our big data problem? What is our goal?**\n",
    "* Build a scalable music recommendation system using a large dataset of songs and their audio features from Spotify.\n",
    "* Given an input (e.g., a song's name), the algorithm will predict and recommend related songs based on their relevance and similarity to the input.\n",
    "* Use Spark/PySpark for processing large-scale data and developing machine learning algorithms.\n",
    "\n",
    "**Why we chose building Recommendation Systems:**\n",
    "* Recommendation systems are widely used in modern digital platforms to enhance user experience (e.g., Spotify, Netflix, Amazon).\n",
    "* Help users discover relevant content, which helps to increase engagement and satisfaction.\n",
    "\n",
    "**Why Spotify dataset?**\n",
    "* Spotify is a leading music streaming platform which has rich data on songs, audio features, and artists.\n",
    "* The dataset provides an opportunity to analyze music preferences and recommend personalized songs or playlists.\n",
    "\n",
    "**What is a big data challenge?**\n",
    "* The solution involves leveraging PySpark’s distributed computing capabilities to handle, transform, and analyze large volumes of data efficiently.\n",
    "* PySpark is well-suited for handling and analyzing big data with its distributed computing capabilities.\n",
    "\n",
    "**Broader applications:**\n",
    "* Insights from the project can extend to other recommendation systems.\n",
    "* Demonstrates the integration of big data tools and machine learning for real-world applications.\n"
   ],
   "id": "9fc38fc12d35af55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Setting up Spark\n",
    "\n",
    "This section is optional. In case that you have not installed Spark, Hadoop, etc. in your local machine, then this part will help setting up Spark in the Jupyter Notebook for running."
   ],
   "id": "9654b2daf089473"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:18:36.674295Z",
     "start_time": "2024-11-18T19:18:36.669438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## OPTIONAL: Setting up Spark in Jupyter Notebook\n",
    "\n",
    "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# !wget https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz\n",
    "# !tar -xvf spark-3.5.3-bin-hadoop3.tgz\n",
    "# !pip install findspark\n",
    "# \n",
    "# import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.3-bin-hadoop3\"\n",
    "# \n",
    "# import findspark\n",
    "# findspark.init()\n",
    "# findspark.find()"
   ],
   "id": "f7c6a9a9e21abfec",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:18:36.694476Z",
     "start_time": "2024-11-18T19:18:36.689538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## OPTIONAL: Test if PySpark is ready to go\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "# \n",
    "# spark = SparkSession.builder.appName(\"Test\").getOrCreate()\n",
    "# print(f\"Spark version:\", spark.version)\n",
    "# \n",
    "# spark.stop()\n",
    "\n",
    "## expected result: 3.5.3 or similar"
   ],
   "id": "4e85d88f72d3ae04",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Collection\n",
    "\n",
    "**Required Tasks:**\n",
    "* Load the dataset into a PySpark DataFrame.\n",
    "* Verify the dataset schema and check if the data is loaded correctly.\n",
    "\n",
    "**Output:** A PySpark DataFrame loaded and ready for processing, with the schema verified.\n"
   ],
   "id": "7bfca0ce77f2b1db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### How we get the dataset?\n",
    "\n",
    "We extracted the dataset from Spotify using Spotify API and the `Spotipy` library in Python.\n",
    "\n",
    "Attached the Python files for extraction and transformation (from JSON to CSV). Please note that these files are for references only, because in order to run those files, you will have to set up a virtual environment."
   ],
   "id": "8a58a580889aaca5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading datasets",
   "id": "f5e7046225ee57ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:19:17.099232Z",
     "start_time": "2024-11-18T19:19:17.085137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ],
   "id": "cefc2a953d7d634c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Program Files\\\\spark-3.5.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:19:36.740403Z",
     "start_time": "2024-11-18T19:19:21.632350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, count\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# initialize a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SpotifyRecommendationSystem\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# load dataset into a DataFrame\n",
    "file_path = \"./dataset/spotify_dataset.csv\" # Note: The dataset file is too large (>250 MB) to commit to a GitHub repo.\n",
    "spotify_df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# display the first few rows\n",
    "spotify_df.show(5)\n"
   ],
   "id": "9bcc09d58d3b4dd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+--------------------+----------+----+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+--------------+\n",
      "|_c0|  artist_name|      track_name|            track_id|popularity|year|   genre|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|duration_ms|time_signature|\n",
      "+---+-------------+----------------+--------------------+----------+----+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+--------------+\n",
      "|  0|   Jason Mraz| I Won't Give Up|53QF56cjZA9RTuuMZ...|        68|2012|acoustic|       0.483| 0.303|  4| -10.058|   1|     0.0429|       0.694|             0.0|   0.115|  0.139|133.406|   240166.0|           3.0|\n",
      "|  1|   Jason Mraz|93 Million Miles|1s8tP3jP4GZcyHDsj...|        50|2012|acoustic|       0.572| 0.454|  3| -10.286|   1|     0.0258|       0.477|        1.37e-05|  0.0974|  0.515|140.182|   216387.0|           4.0|\n",
      "|  2|Joshua Hyslop|Do Not Let Me Go|7BRCa8MPiyuvr2VU3...|        57|2012|acoustic|       0.409| 0.234|  3| -13.711|   1|     0.0323|       0.338|           5e-05|  0.0895|  0.145|139.832|   158960.0|           4.0|\n",
      "|  3| Boyce Avenue|        Fast Car|63wsZUhUZLlh1Osyr...|        58|2012|acoustic|       0.392| 0.251| 10|  -9.845|   1|     0.0363|       0.807|             0.0|  0.0797|  0.508|204.961|   304293.0|           4.0|\n",
      "|  4| Andrew Belle|Sky's Still Blue|6nXIYClvJAfi6ujLi...|        54|2012|acoustic|        0.43| 0.791|  6|  -5.419|   0|     0.0302|      0.0726|          0.0193|    0.11|  0.217|171.864|   244320.0|           4.0|\n",
      "+---+-------------+----------------+--------------------+----------+----+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Inspection and Validation\n",
    "\n",
    "In this section, we will do the following tasks:\n",
    "\n",
    "* Check the data schema with column names and data types.\n",
    "* Convert data types if needed.\n",
    "* Check for the summary statistics of the dataset.\n",
    "* Check for missing values. Handle missing values properly.\n",
    "* Check for outliers. Handle the outliers.\n",
    "* Check for distinct values."
   ],
   "id": "ed3a962387bf81e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:19:42.244185Z",
     "start_time": "2024-11-18T19:19:42.235535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print schema to verify column names and data types\n",
    "spotify_df.printSchema()"
   ],
   "id": "4123d71c842833d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- danceability: string (nullable = true)\n",
      " |-- energy: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- loudness: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- speechiness: string (nullable = true)\n",
      " |-- acousticness: string (nullable = true)\n",
      " |-- instrumentalness: string (nullable = true)\n",
      " |-- liveness: string (nullable = true)\n",
      " |-- valence: double (nullable = true)\n",
      " |-- tempo: double (nullable = true)\n",
      " |-- duration_ms: double (nullable = true)\n",
      " |-- time_signature: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Data type conversins:**\n",
    "\n",
    "From [Spotify's API documentation](https://developer.spotify.com/documentation/web-api/reference/get-audio-features) about track's audio features, each feature has its own meaning and data types. So we will convert the data types of features in our dataset to match Spotify's documentation."
   ],
   "id": "74c1c8744d12f801"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:19:45.123443Z",
     "start_time": "2024-11-18T19:19:44.864526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# casting columns to their appropriate data types as per Spotify's documentation\n",
    "spotify_df = spotify_df \\\n",
    "    .withColumn(\"popularity\", col(\"popularity\").cast(\"int\")) \\\n",
    "    .withColumn(\"year\", col(\"year\").cast(\"int\")) \\\n",
    "    .withColumn(\"danceability\", col(\"danceability\").cast(\"float\")) \\\n",
    "    .withColumn(\"energy\", col(\"energy\").cast(\"float\")) \\\n",
    "    .withColumn(\"key\", col(\"key\").cast(\"int\")) \\\n",
    "    .withColumn(\"loudness\", col(\"loudness\").cast(\"float\")) \\\n",
    "    .withColumn(\"mode\", col(\"mode\").cast(\"int\")) \\\n",
    "    .withColumn(\"speechiness\", col(\"speechiness\").cast(\"float\")) \\\n",
    "    .withColumn(\"acousticness\", col(\"acousticness\").cast(\"float\")) \\\n",
    "    .withColumn(\"instrumentalness\", col(\"instrumentalness\").cast(\"float\")) \\\n",
    "    .withColumn(\"liveness\", col(\"liveness\").cast(\"float\")) \\\n",
    "    .withColumn(\"tempo\", col(\"tempo\").cast(\"float\")) \\\n",
    "    .withColumn(\"time_signature\", col(\"time_signature\").cast(\"int\"))\n",
    "\n",
    "# re-check the updated schema\n",
    "spotify_df.printSchema()\n"
   ],
   "id": "90e820975ec6874d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- popularity: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- danceability: float (nullable = true)\n",
      " |-- energy: float (nullable = true)\n",
      " |-- key: integer (nullable = true)\n",
      " |-- loudness: float (nullable = true)\n",
      " |-- mode: integer (nullable = true)\n",
      " |-- speechiness: float (nullable = true)\n",
      " |-- acousticness: float (nullable = true)\n",
      " |-- instrumentalness: float (nullable = true)\n",
      " |-- liveness: float (nullable = true)\n",
      " |-- valence: double (nullable = true)\n",
      " |-- tempo: float (nullable = true)\n",
      " |-- duration_ms: double (nullable = true)\n",
      " |-- time_signature: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:19:47.948230Z",
     "start_time": "2024-11-18T19:19:47.335540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# count total rows in the dataset\n",
    "total_rows = spotify_df.count()\n",
    "print(f\"Total rows in the dataset: {total_rows}\")"
   ],
   "id": "10707cba07e8edda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in the dataset: 1159764\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Remarks: The dataset contains 1,159,764 rows, which is quite large, indicating the need for big data tools like PySpark.",
   "id": "de887a331b3feed2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Check for Summary Statistics:**\n",
    "\n",
    "Next, we want to check for the summary statistics of the dataset. In [Spark](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.describe.html), if using `.describe()` method, it will by default calculate the stats for all columns including both numerical and non-numerical (string) columns. Therefore, we have to filter out the columns based on their data types as follows."
   ],
   "id": "40fe6fa2e6568d95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:27:02.538447Z",
     "start_time": "2024-11-18T19:27:00.213767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# filter numeric columns using dtypes\n",
    "numeric_columns = [name for name, dtype in spotify_df.dtypes if dtype in ('int', 'bigint', 'double', 'float', 'decimal')]\n",
    "\n",
    "# select only numeric columns\n",
    "numeric_df = spotify_df.select(*numeric_columns)\n",
    "\n",
    "# show summary statistics for numerical columns only\n",
    "numeric_df.describe().show()"
   ],
   "id": "9b3ddea969b36fb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+\n",
      "|summary|              _c0|        popularity|              year|     danceability|            energy|               key|          loudness|             mode|        speechiness|       acousticness|   instrumentalness|           liveness|            valence|             tempo|       duration_ms|    time_signature|\n",
      "+-------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+\n",
      "|  count|          1159764|           1158091|           1159141|          1158580|           1159356|           1159602|           1159670|          1159731|            1159748|            1159756|            1159761|            1159762|            1159764|           1159764|           1159764|           1159764|\n",
      "|   mean|659061.3219129064|18.393719491818864|2010.1450030669264|1.151689557821435|0.8750431817828228| 5.421848185843074| -8.90125644459297|0.642995660200512|0.10187417859253778|0.32384287579000465|0.25511809159462906|0.22280301037863148|0.45543146363409936| 121.2262622110439|249223.50955903548|219.83662710689416|\n",
      "| stddev|428549.1535705906|15.888212092912061| 60.52526727918657|35.12214257953176|21.720800387148365|17.144522698291876|11.435647099557297|7.026148812516287| 5.2942646995895775| 3.2571918436446836|  2.666910391613436| 0.2258207729737689| 0.2759459120284293|30.103371885007203| 149607.9337131288| 8673.273461566454|\n",
      "|    min|                0|                 0|                 0|              0.0|               0.0|                 0|             -58.1|              -43|            -36.843|            -36.639|            -38.845|            -29.312|            -29.777|           -24.073|           -17.417|               -22|\n",
      "|    max|          1473395|               100|              2023|           2023.0|            2023.0|              2023|            2023.0|             2023|             2017.0|             2017.0|             2009.0|               10.0|               11.0|           249.993|         6000495.0|           1358453|\n",
      "+-------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Remarks for summary statistics:**\n",
    "\n",
    "* `popularity`: Ranges from 0 to 100, indicating a reasonable scale for popularity.\n",
    "* `year`: The dataset includes tracks from 0 to 2023. The value 0 seems anomalous and might need further investigation.\n",
    "* Other features like `danceability`, `energy`, `tempo`, and `duration_ms` have a wide range of values, which may need normalization or standardization for machine learning.\n",
    "* Potential outliers: Columns like `tempo` (min = -24.073) and `loudness` (min = -58.1) have unusual values that might indicate outliers or data entry issues."
   ],
   "id": "ce1bd7a6f443e685"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T21:08:49.392592Z",
     "start_time": "2024-11-18T21:08:47.792188Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+--------+----------+----+-----+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-----+-----------+--------------+\n",
      "|_c0|artist_name|track_name|track_id|popularity|year|genre|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|tempo|duration_ms|time_signature|\n",
      "+---+-----------+----------+--------+----------+----+-----+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-----+-----------+--------------+\n",
      "|  0|          0|         0|       0|      1673| 623|    0|        1184|   408|162|      94|  33|         16|           8|               3|       2|      0|    0|          0|             0|\n",
      "+---+-----------+----------+--------+----------+----+-----+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-----+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13,
   "source": [
    "# check for missing values in each column\n",
    "missing_values = spotify_df.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c in spotify_df.columns\n",
    "])\n",
    "missing_values.show()"
   ],
   "id": "8566923377d65c27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Remarks for missing values:**\n",
    "\n",
    "* Columns with missing data: popularity (1,673 missing values), year (623), and others such as  danceability, energy, key, loudness, and mode.\n",
    "* Given the dataset has over 1.15M rows, the proportion of missing data is extremely small (less than 0.1% for all affected columns).\n",
    "* In this case, we will drop rows with missing values in features that are critical for our recommendation system."
   ],
   "id": "96848fd8d14259c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T21:20:44.590821Z",
     "start_time": "2024-11-18T21:20:43.844665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# drop rows with missing data in critical columns\n",
    "columns_to_check = ['popularity', 'year', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness']\n",
    "\n",
    "spotify_df_clean = spotify_df.na.drop(subset=columns_to_check)\n",
    "\n",
    "# verify the number of rows after dropping\n",
    "cleaned_rows = spotify_df_clean.count()\n",
    "print(f\"Rows after dropping missing data: {cleaned_rows}\")\n",
    "\n",
    "dropped_rows = total_rows - cleaned_rows\n",
    "print(f\"Number of rows dropped: {dropped_rows}\")\n"
   ],
   "id": "47e94b8710ab756",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after dropping missing data: 1158091\n",
      "Number of rows dropped: 1673\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Anomalies and Outliers**:\n",
    "\n",
    "We will investigate the folloiwng things:\n",
    "\n",
    "* Check for distinct values of `year` column to make sure no abnormal values (such as 1500).\n",
    "* \n",
    "\n"
   ],
   "id": "2ba0ba961fd386ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:25:36.213223Z",
     "start_time": "2024-11-18T22:25:35.446999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get distinct years and their frequencies\n",
    "year_distribution = spotify_df_clean.groupBy(\"year\").count().orderBy(\"year\")\n",
    "\n",
    "year_distribution.show(50)"
   ],
   "id": "b1e523b5392689d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2000|43944|\n",
      "|2001|42316|\n",
      "|2002|42084|\n",
      "|2003|42250|\n",
      "|2004|43293|\n",
      "|2005|43708|\n",
      "|2006|45419|\n",
      "|2007|45920|\n",
      "|2008|47336|\n",
      "|2009|46810|\n",
      "|2010|46818|\n",
      "|2011|46381|\n",
      "|2012|54725|\n",
      "|2013|53105|\n",
      "|2014|53120|\n",
      "|2015|51569|\n",
      "|2016|40246|\n",
      "|2017|56171|\n",
      "|2018|56541|\n",
      "|2019|55739|\n",
      "|2020|55035|\n",
      "|2021|53529|\n",
      "|2022|53637|\n",
      "|2023|38395|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Remarks for `year`: The years range from 2000 to 2023, which are expected and normal.",
   "id": "a854ab265f1643f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Check for anomalies in numerical columns:**\n",
    "\n",
    "Compare data against the value ranges specified in the [Spotify documentation](https://developer.spotify.com/documentation/web-api/reference/get-audio-features):\n",
    "* acousticness: [0, 1]\n",
    "* danceability: [0, 1]\n",
    "* energy: [0, 1] \n",
    "* instrumentalness: [0, 1]\n",
    "* key: [-1, 11]\n",
    "* liveness: [0, 1]\n",
    "* mode: {0, 1}\n",
    "* speechiness: [0, 1]\n",
    "* tempo: Typically [1, 250], (note: this is a typical range; Spotify docs don't strictly enforce this.)\n",
    "* time_signature: [3, 7]\n",
    "* valence: [0, 1]"
   ],
   "id": "24aac1c3616ec577"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T23:03:52.520042Z",
     "start_time": "2024-11-18T23:03:41.914645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the range checks for each feature\n",
    "range_checks = {\n",
    "    \"acousticness\": (0, 1),\n",
    "    \"danceability\": (0, 1),\n",
    "    \"energy\": (0, 1),\n",
    "    \"instrumentalness\": (0, 1),\n",
    "    \"key\": (-1, 11),\n",
    "    \"liveness\": (0, 1),\n",
    "    \"mode\": (0, 1),\n",
    "    \"speechiness\": (0, 1),\n",
    "    \"tempo\": (1, 250),\n",
    "    \"time_signature\": (3, 7),\n",
    "    \"valence\": (0, 1),\n",
    "}\n",
    "\n",
    "# identify anomalies in each feature\n",
    "anomalies = {}\n",
    "for feature, (min_val, max_val) in range_checks.items():\n",
    "    anomalies[feature] = spotify_df_clean.filter((col(feature) < min_val) | (col(feature) > max_val)).count()\n",
    "\n",
    "# print the anomalies count for each feature\n",
    "for feature, count in anomalies.items():\n",
    "    print(f\"Number of anomalies in {feature}: {count}\")\n"
   ],
   "id": "99b55d3ed6c61adf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalies in acousticness: 0\n",
      "Number of anomalies in danceability: 0\n",
      "Number of anomalies in energy: 0\n",
      "Number of anomalies in instrumentalness: 0\n",
      "Number of anomalies in key: 0\n",
      "Number of anomalies in liveness: 0\n",
      "Number of anomalies in mode: 0\n",
      "Number of anomalies in speechiness: 0\n",
      "Number of anomalies in tempo: 1198\n",
      "Number of anomalies in time_signature: 13816\n",
      "Number of anomalies in valence: 0\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "From the results:\n",
    "\n",
    "* No Anomalies:\n",
    "    * Most features (acousticness, danceability, energy, instrumentalness, etc.) have no anomalies. These are clean and can be used as-is.\n",
    "* tempo Anomalies:\n",
    "    * 1,198 anomalies fall outside the range [1, 250]. These might include invalid or outlier values (e.g., extremely high or low BPM).\n",
    "* time_signature Anomalies:\n",
    "    * 13,816 anomalies fall outside the range [3, 7]. These could represent tracks with unusual time signatures, potentially errors or special cases."
   ],
   "id": "875d6ac86a79c69f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T23:22:06.455529Z",
     "start_time": "2024-11-18T23:22:05.521169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show rows with tempo anomalies\n",
    "tempo_anomalies = spotify_df_clean.filter((col(\"tempo\") < 1) | (col(\"tempo\") > 250))\n",
    "\n",
    "# Descriptive statistics for tempo anomalies\n",
    "tempo_anomalies.describe(\"tempo\").show()\n"
   ],
   "id": "d00741f3b2fbb380",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|summary|tempo|\n",
      "+-------+-----+\n",
      "|  count| 1198|\n",
      "|   mean|  0.0|\n",
      "| stddev|  0.0|\n",
      "|    min|  0.0|\n",
      "|    max|  0.0|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T23:22:26.392807Z",
     "start_time": "2024-11-18T23:22:25.456846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show rows with time_signature anomalies\n",
    "time_signature_anomalies = spotify_df_clean.filter((col(\"time_signature\") < 3) | (col(\"time_signature\") > 7))\n",
    "\n",
    "# Descriptive statistics for time_signature anomalies\n",
    "time_signature_anomalies.describe(\"time_signature\").show()\n"
   ],
   "id": "979f1c940d61d660",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|     time_signature|\n",
      "+-------+-------------------+\n",
      "|  count|              13816|\n",
      "|   mean| 0.9111899247249565|\n",
      "| stddev|0.28447970650303633|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Distinct values**\n",
    "\n",
    "Let's check the distinct values in the most important columns: `artist_name`, `track_name`, `genre`."
   ],
   "id": "5e5b6b8d65f022c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T23:19:27.664746Z",
     "start_time": "2024-11-18T23:19:23.000516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count distinct values in key columns\n",
    "key_columns = ['artist_name', 'track_name', 'genre']\n",
    "distinct_counts = {col_name: spotify_df.select(col_name).distinct().count() for col_name in key_columns}\n",
    "\n",
    "for col_name, count in distinct_counts.items():\n",
    "    print(f\"Distinct values in {col_name}: {count}\")"
   ],
   "id": "247b305f4ada2822",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values in artist_name: 64159\n",
      "Distinct values in track_name: 882285\n",
      "Distinct values in genre: 392\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Since `duration_ms` has no missing values, we will validate for unusual entries like negatives or extreme outliers in the dataset. For example, we will filter out the songs that have negativ or extremely long durations (> 10 minutes). Songs with negativ durations may mean corrupted data. Extremely long songs might need special handling (e.g. audiobooks or podcasts).",
   "id": "4a9f5ee25cdffb01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Validate for negative or extremely high durations (e.g., > 10 minutes in milliseconds)\n",
    "negative_durations = spotify_df.filter(col(\"duration_ms\") < 0).count()\n",
    "long_durations = spotify_df.filter(col(\"duration_ms\") > 10 * 60 * 1000).count()\n",
    "\n",
    "print(f\"Number of negativ durations: {negative_durations}\")\n",
    "print(f\"Number of extremely long durations (>10 minutes): {long_durations}\")"
   ],
   "id": "abe0ddd1d9799e62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "baef496f7594381b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Quick summary:**\n",
    "\n",
    "Our group's recommendation system will use Content-Based Filtering method instead of Collaborative filtering. Content-Based Filtering method analyzes the audio characteristics of songs you’ve previously enjoyed, then the model will make personalized suggestions. We do not use Collaborative filtering or user-based filtering method becuase we cannot collect the information related to Spotify's users such as `user_id`.\n",
    "   \n",
    "The target variable you are modeling and potentially interesting features of the dataset you will be focusing on during the project. \n",
    "\n",
    "**Target variables:**\n",
    "\n",
    "Based on this focus, we defined that the target variable is `track_id`, which means that we will recommend **tracks** based on their attributes.\n",
    "\n",
    "**Features:**\n",
    "\n",
    "We catogorized the features into corresponding groups as follows:\n",
    "\n",
    "1. Key musical features:\n",
    "\n",
    "* danceability: Indicates how suitable a track is for dancing.\n",
    "* energy: Reflects the intensity and activity of the track.\n",
    "* valence: Captures the musical positivity (happy/sad).\n",
    "* tempo: The speed or pace of the track in beats per minute.\n",
    "\n",
    "2. Categorical and context-based features:\n",
    "\n",
    "* genre: Key for grouping similar tracks into clusters.\n",
    "* year: Tracks trends and preferences over time.\n",
    "* popularity: Acts as a secondary metric to boost recommendations for tracks that align with user preferences but are also well-received.\n",
    "\n",
    "These features are not very important or relevant or already duplicated with other features above. So we might or might not use them for modelling depending on the performance and the needs for feature engineering. \n",
    "\n",
    "* acousticness: Degree of acoustic sound in the track.\n",
    "* instrumentalness: Likelihood of the track being instrumental.\n",
    "* liveness: Measures the presence of an audience in the track.\n",
    "* loudness: Reflects the dynamic range and intensity.\n",
    "* key and mode: Capture musical scale and tonality.\n",
    "* time_signature: Represents the rhythm structure of the track.\n"
   ],
   "id": "fd5727c70382ecd9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Filtering",
   "id": "8aa5692fb3749b56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5b651c9d6dcd98c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exploratory Data Analysis (EDA) - IN PROGRESS\n",
    "\n",
    "In this section, we will explore the dataset to find any patterns and correlations in the dataset. We will use some visualizations to show the trends and also validate the preprocessing in ealier steps.\n",
    "\n",
    "Here are some tasks that we will perform:\n",
    "\n",
    "* Check the distribution of numerical features.\n",
    "* Correlation analysis.\n",
    "* Analyze the popularity trends over year and by genre.\n",
    "* Check the distribution by genre.\n",
    "* Plot the relationship between enegery and danceability.\n",
    "* Plot the relationship between valence and tempo.\n",
    "* etc."
   ],
   "id": "371d103682e4c25e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Distribution of numerical features\n",
    "\n",
    "In this section, we will check the distribution of important numerical features (e.g., popularity, danceability, tempo, valence) to understand data spread and skewness.\n",
    "\n",
    "More info about each audio feature can be found in [Spotify's API documentation](https://developer.spotify.com/documentation/web-api/reference/get-audio-features).\n",
    "\n",
    "Reasons to choose these numerical features:\n",
    "\n",
    "* Popularity: This is a key metric for user preference and relevance. Tracks with higher popularity are more likely to be recommended.\n",
    "* Danceability: This feature reflects how suitable a track is for dancing—an important factor in user satisfaction for genres like pop or electronic.\n",
    "* Energy: This feature shows the intensity and activity level of a song, which can help classify songs by mood or genre (e.g., calm vs. energetic).\n",
    "* Tempo: This is the speed of a song. THis is a key factor for many users when selecting playlists (e.g., playlists for workout, study, or relaxation).\n",
    "* Valence: This indicates the emotional tone of the song (happy vs. sad), important for personalized recommendations based on mood. \n",
    "* Duration (`duration_ms`): This feature is relevant for filtering or grouping songs by length (e.g., short tracks for a quick playlist or long tracks for background music)."
   ],
   "id": "689a88834a73f585"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select numerical features to visualize\n",
    "numerical_features = [\"popularity\", \"danceability\", \"energy\", \"tempo\", \"valence\", \"duration_ms\"]\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas for plotting\n",
    "numerical_data = spotify_df.select(numerical_features).sample(fraction=0.01).toPandas()\n",
    "\n",
    "# Plot histograms for each feature\n",
    "for feature in numerical_features:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(numerical_data[feature].dropna(), bins=30, alpha=0.7)\n",
    "    plt.title(f\"Distribution of {feature}\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ],
   "id": "6c6974063fd68271",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4df259b618c8865e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Correlation analysis - IN PROGRSS",
   "id": "5a75d4e5f57d5b6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pandas as pd\n",
    "\n",
    "# Assemble features into a vector for correlation computation\n",
    "vector_col = \"features_vector\"\n",
    "assembler = VectorAssembler(inputCols=numerical_features, outputCol=vector_col)\n",
    "spotify_df_vector = assembler.transform(spotify_df.select(numerical_features))\n",
    "\n",
    "# Compute Pearson correlation matrix\n",
    "correlation_matrix = Correlation.corr(spotify_df_vector, vector_col, \"pearson\").head()[0].toArray()\n",
    "\n",
    "# Convert to Pandas DataFrame for easier visualization\n",
    "correlation_df = pd.DataFrame(correlation_matrix, columns=numerical_features, index=numerical_features)\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_df)\n",
    "\n",
    "# Visualize the correlation matrix\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_df, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n"
   ],
   "id": "e0070e0cbc80767e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f11feec1ea4f4c72",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
